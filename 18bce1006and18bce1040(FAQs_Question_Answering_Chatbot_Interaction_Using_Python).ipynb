{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18bce1006and18bce1040(FAQs Question Answering Chatbot Interaction Using Python)",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFqbA9aWtVFjcmquVpWzzw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coolShub/DiceGame/blob/main/18bce1006and18bce1040(FAQs_Question_Answering_Chatbot_Interaction_Using_Python).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-JUx_-W-6Ur"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGemprr-11-0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"FAQ_MachineLearningInterview_com.csv\", delimiter='|')\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-TUdwvLBQSk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3Ffu7IX2FpB"
      },
      "source": [
        "\n",
        "import re\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "#from nltk.stem.lancaster import LancasterStemmer\n",
        "#st = LancasterStemmer()\n",
        "\n",
        "def clean_sentence(sentence , stopwords=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
        "    #sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
        "    \n",
        "    if stopwords:\n",
        "        sentence = remove_stopwords(sentence)\n",
        "\n",
        "    #sent_stemmed=''\n",
        "    #for word in sentence.split():\n",
        "    #    sent_stemmed += ' ' + st.stem(word)\n",
        "    #sentence = sent_stemmed\n",
        "    return sentence\n",
        "\n",
        "def get_cleaned_sentences(df,stopwords=False):\n",
        "    sents=df[[\"questions\"]];\n",
        "    cleaned_sentences=[]\n",
        "    \n",
        "    for index,row in df.iterrows():\n",
        "        #print(index,row)\n",
        "        cleaned = clean_sentence(row[\"questions\"],stopwords);\n",
        "        cleaned_sentences.append(cleaned)\n",
        "\n",
        "    return cleaned_sentences;\n",
        "\n",
        "cleaned_sentences = get_cleaned_sentences(df,stopwords=True)\n",
        "print(cleaned_sentences);\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "cleaned_sentences_with_stopwords=get_cleaned_sentences(df,stopwords=False)\n",
        "print(cleaned_sentences_with_stopwords);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWxwooTO2MJc"
      },
      "source": [
        "import numpy\n",
        "\n",
        "sentences = cleaned_sentences_with_stopwords\n",
        "#sentences = cleaned_sentences\n",
        "\n",
        "sentence_words = [[word for word in document.split()] for document in sentences]\n",
        "print(sentence_words)\n",
        "\n",
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(sentence_words)\n",
        "\n",
        "for key,value in dictionary.items():\n",
        "    print(key, \" : \", value)\n",
        "\n",
        "import pprint\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in sentence_words]\n",
        "\n",
        "for sent,embedding in zip(sentences,bow_corpus):\n",
        "    print(sent)\n",
        "    print(embedding)\n",
        "\n",
        "#question_orig=\"do I need to learn algorithms to be a data scientist ?\"\n",
        "question_orig=\"What does a data scientist usually do ?\"\n",
        "# question_orig=input(\"Enter the query\")\n",
        "question=clean_sentence(question_orig,stopwords=False)\n",
        "question_embedding=dictionary.doc2bow(question.split())\n",
        "\n",
        "print(\"\\n\\n\",question,\"\\n\",question_embedding)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPsrqnmv2T2t"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def retrieveAndPrintFAQAnswer(question_embedding,sentence_embeddings,FAQdf,sentences):\n",
        "    # max_sim=-1\n",
        "    # index_sim=-1\n",
        "\n",
        "    total_lst = []\n",
        "    for index,faq_embedding in enumerate(sentence_embeddings):\n",
        "        #sim=cosine_similarity(embedding.reshape(1,-1),question_embedding.reshape(1,-1))[0][0]\n",
        "        sim=cosine_similarity(faq_embedding,question_embedding)[0][0]\n",
        "        print(index,sim,sentences[index])\n",
        "        total_lst.append((sim, index))\n",
        "        # if sim > max_sim:\n",
        "        #     max_sim = sim\n",
        "        #     index_sim = index\n",
        "    \n",
        "    total_lst.sort(reverse=True)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Question: \",question)\n",
        "\n",
        "    # print(\"index             sim                   ques\")\n",
        "    for siml, index in total_lst:\n",
        "        if siml == total_lst[0][0]:\n",
        "            print(\"\\n\")\n",
        "            # print(\"\\n\")\n",
        "            print(\"Retrieved: \",FAQdf.iloc[index,0])\n",
        "            print(FAQdf.iloc[index,1])\n",
        "            # print(index, \"               \", siml, \"               \", sentences[index])\n",
        "    # print(total_lst)\n",
        "\n",
        "\n",
        "retrieveAndPrintFAQAnswer(question_embedding,bow_corpus,df,sentences)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY_ceEG-2YBB"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "glove_model=None\n",
        "\n",
        "try:\n",
        "    glove_model=gensim.models.KeyedVectors.load(\"./glovemodel.mod\")\n",
        "    print(\"Loaded glove model\")\n",
        "except:\n",
        "    glove_model = api.load('glove-twitter-25')\n",
        "    glove_model.save(\"./glovemodel.mod\")\n",
        "    print(\"Saved glove model\")\n",
        "\n",
        "\n",
        "\n",
        "w2v_model=None\n",
        "\n",
        "try:\n",
        "    w2v_model=gensim.models.KeyedVectors.load(\"./w2vecmodel.mod\")\n",
        "    print(\"Loaded w2v model\")\n",
        "except:\n",
        "    w2v_model = api.load('word2vec-google-news-300')\n",
        "    w2v_model.save(\"./w2vecmodel.mod\")\n",
        "    print(\"Saved w2v model\")\n",
        "\n",
        "\n",
        "w2vec_embedding_size=len(w2v_model['computer'])\n",
        "glove_embedding_size=len(glove_model['computer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k75QqXVl2hcZ"
      },
      "source": [
        "def getWordVec(word, model):\n",
        "\tsamp = model['computer']\n",
        "\tvec = [0]*len(samp)\n",
        "\ttry:\n",
        "\t\tvec = model[word]\n",
        "\texcept:\n",
        "\t\tvec = [0]*len(samp)\n",
        "\treturn (vec)\n",
        "\t\n",
        "def getPhraseEmbedding(phrase, embeddingmodel):\n",
        "\tsamp = getWordVec('computer', embeddingmodel)\n",
        "\tvec = numpy.array([0]*len(samp))\n",
        "\tden = 0\n",
        "\tfor word in phrase.split():\n",
        "\t\tprint(word)\n",
        "\t\tden = den + 1\n",
        "\t\tvec = vec + numpy.array(getWordVec(word, embeddingmodel))\n",
        "\t\t\n",
        "\t#vec  vec/den;\n",
        "\t#return (vec.tolist())\n",
        "\treturn vec.reshape(1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anhPiTNlQG20"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf-rVfj-QH0P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTngFYxfQJBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzYKK7LY2ixq"
      },
      "source": [
        "#With w2Vec\n",
        "\n",
        "sent_embeddings = []\n",
        "for sent in cleaned_sentences:\n",
        "\tsent_embeddings.append(getPhraseEmbedding(sent, w2v_model))\n",
        "\t\n",
        "question_embedding = getPhraseEmbedding(question, w2v_model)\n",
        "\n",
        "retrieveAndPrintFAQAnswer(question_embedding, sent_embeddings, df, cleaned_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqCU2dro82cX"
      },
      "source": [
        "#With BOW, word2Vec with stopwords removed\n",
        "question_new = \"Is it required to have background in algorithms and complexity for data scientist roles\"\n",
        "\n",
        " \n",
        "question = clean_sentence(question_new, stopwords=True)\n",
        "clean_sentences = get_cleaned_sentences(df, stopwords=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1fgOxX1-dqm"
      },
      "source": [
        "\n",
        "#Try BOW\n",
        "question_embedding = dictionary.doc2bow(question.lower().split())\n",
        "print(\"\\n\\n With BOW\\n\\n\")\n",
        "retrieveAndPrintFAQAnswer(question_embedding, bow_corpus, df,clean_sentences )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoGEOyXG-kvK"
      },
      "source": [
        "\n",
        "sent_embeddings = []\n",
        "for sent in cleaned_sentences:\n",
        "    sent_embeddings.append(getPhraseEmbedding(sent, w2v_model))\n",
        "\n",
        " \n",
        "question_embedding = getPhraseEmbedding(question, w2v_model)\n",
        "\n",
        " \n",
        "\n",
        "print(\"\\n With Word2Vec\\n\\n\")\n",
        "retrieveAndPrintFAQAnswer(question_embedding, sent_embeddings, df, cleaned_sentences)\n",
        "\n",
        " \n",
        "question = clean_sentence(question_new, stopwords=False)\n",
        "cleaned_sentences = get_cleaned_sentences(df, stopwords=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}